import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
import joblib
import os
import pathlib

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------- 1. åŠ è½½å¤–éƒ¨CSVæ–‡ä»¶ï¼ˆå½»åº•ç§»é™¤æ‰€æœ‰è°ƒè¯•è¾“å‡ºï¼‰ ----------------------
@st.cache_data
def load_data():
    # è„šæœ¬ç»å¯¹è·¯å¾„ï¼ˆä»…ä¿ç•™è·¯å¾„é€»è¾‘ï¼Œæ— ä»»ä½•æ‰“å°ï¼‰
    script_dir = pathlib.Path(__file__).parent.absolute()
    csv_path = script_dir / "insurance-chinese.csv"
    
    # ä»…åœ¨æ–‡ä»¶ä¸å­˜åœ¨æ—¶æ˜¾ç¤ºé”™è¯¯ï¼ˆæ— å…¶ä»–æç¤ºï¼‰
    if not os.path.exists(csv_path):
        st.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨ï¼š{csv_path}")
        st.stop()
    
    # å°è¯•ç¼–ç ï¼ˆæ— ä»»ä½•æç¤ºï¼Œå¤±è´¥åˆ™ç»§ç»­ï¼‰
    encodings = ["utf-8-sig", "utf-8", "gbk", "gb2312", "latin-1"]
    for encoding in encodings:
        try:
            df = pd.read_csv(csv_path, encoding=encoding)
            df.columns = df.columns.str.strip().str.replace(" ", "")
            # æ£€æŸ¥å¿…è¦åˆ—ï¼ˆä»…åœ¨ç¼ºå¤±æ—¶æ˜¾ç¤ºé”™è¯¯ï¼‰
            required_cols = ["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ", "åŒ»ç–—è´¹ç”¨"]
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                st.error(f"CSVç¼ºå°‘åˆ—ï¼š{', '.join(missing_cols)}")
                st.stop()
            X = df[["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]]
            y = df["åŒ»ç–—è´¹ç”¨"]
            return X, y, df
        except:
            pass  # å½»åº•å…³é—­æ‰€æœ‰ç¼–ç ç›¸å…³æç¤º
    
    # æ‰€æœ‰ç¼–ç å¤±è´¥æ—¶æ‰æ˜¾ç¤ºé”™è¯¯
    st.error("æ— æ³•è¯»å–CSVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ç¼–ç æ ¼å¼")
    st.stop()

# ---------------------- 2. æ¨¡å‹è®­ç»ƒä¸ä¿å­˜ ----------------------
def train_model(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    categorical_features = ["æ€§åˆ«", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]
    numerical_features = ["å¹´é¾„", "å­å¥³æ•°é‡"]
    
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numerical_features),
            ("cat", OneHotEncoder(drop="first", sparse_output=False), categorical_features)
        ]
    )
    
    model = Pipeline(steps=[
        ("preprocessor", preprocessor),
        ("regressor", RandomForestRegressor(n_estimators=100, random_state=42))
    ])
    
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    model_path = pathlib.Path(__file__).parent.absolute() / "model.pkl"
    joblib.dump(model, model_path)
    
    return model, r2, mae

# ---------------------- 3. åŠ è½½æ¨¡å‹ ----------------------
def load_model():
    model_path = pathlib.Path(__file__).parent.absolute() / "model.pkl"
    if os.path.exists(model_path):
        try:
            return joblib.load(model_path)
        except:
            X, y, _ = load_data()
            model, _, _ = train_model(X, y)
            return model
    else:
        X, y, _ = load_data()
        model, _, _ = train_model(X, y)
        return model

# ---------------------- 4. Webç•Œé¢ ----------------------
def main():
    st.sidebar.title("ğŸ§­ å¯¼èˆª")
    page = st.sidebar.radio(
        "",
        ["ç®€ä»‹", "é¢„æµ‹åŒ»ç–—è´¹ç”¨"],
        index=1
    )
    
    if page == "ç®€ä»‹":
        show_introduction()
    else:
        show_prediction_page()

def show_introduction():
    st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    st.markdown("""
    ## ğŸ“‹ ç³»ç»Ÿç®€ä»‹
    
    æœ¬ç³»ç»Ÿæ˜¯åŸºäºæœºå™¨å­¦ä¹ çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·ï¼Œæ—¨åœ¨ä¸ºä¿é™©å…¬å¸å’ŒåŒ»ç–—æœºæ„æä¾›å‡†ç¡®çš„è´¹ç”¨é¢„æµ‹å‚è€ƒã€‚
    
    ### ğŸ¯ ä¸»è¦åŠŸèƒ½
    - **æ™ºèƒ½é¢„æµ‹**: åŸºäºéšæœºæ£®æ—ç®—æ³•ï¼Œå‡†ç¡®é¢„æµ‹ä¸ªäººå¹´åº¦åŒ»ç–—è´¹ç”¨
    - **å¤šå› ç´ åˆ†æ**: ç»¼åˆè€ƒè™‘å¹´é¾„ã€æ€§åˆ«ã€BMIã€å¸çƒŸçŠ¶å†µã€å­å¥³æ•°é‡ã€åœ°åŒºç­‰å› ç´ 
    - **é£é™©è¯„ä¼°**: è‡ªåŠ¨è¯†åˆ«é«˜é£é™©å› ç´ å¹¶æä¾›å¥åº·å»ºè®®
    - **å®æ—¶è®¡ç®—**: è¾“å…¥ä¿¡æ¯åå³æ—¶è·å¾—é¢„æµ‹ç»“æœ
    
    ### ğŸ“Š æ•°æ®è¯´æ˜
    - è®­ç»ƒæ•°æ®åŒ…å«1000+çœŸå®ä¿é™©ç†èµ”è®°å½•
    - æ¨¡å‹å‡†ç¡®ç‡è¾¾åˆ°85%ä»¥ä¸Š
    - æ”¯æŒä¸­å›½åœ°åŒºçš„åŒ»ç–—è´¹ç”¨é¢„æµ‹
    
    ### ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹
    - ä½¿ç”¨scikit-learnæœºå™¨å­¦ä¹ åº“
    - éšæœºæ£®æ—å›å½’ç®—æ³•
    - æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
    - äº¤äº’å¼Webç•Œé¢
    
    ### ğŸ“ ä½¿ç”¨è¯´æ˜
    1. ç‚¹å‡»å·¦ä¾§å¯¼èˆªä¸­çš„"é¢„æµ‹åŒ»ç–—è´¹ç”¨"
    2. å¡«å†™è¢«ä¿é™©äººçš„åŸºæœ¬ä¿¡æ¯
    3. ç‚¹å‡»"é¢„æµ‹åŒ»ç–—è´¹ç”¨"æŒ‰é’®
    4. æŸ¥çœ‹é¢„æµ‹ç»“æœå’Œé£é™©æç¤º
    
    ---
    
    ğŸ’¡ **æç¤º**: é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åŒ»ç–—è´¹ç”¨å¯èƒ½å› ä¸ªäººå¥åº·çŠ¶å†µã€åŒ»ç–—æ”¿ç­–ç­‰å› ç´ è€Œæœ‰æ‰€ä¸åŒã€‚
    """)

def show_prediction_page():
    st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    st.markdown("åŸºäºå¤–éƒ¨CSVæ•°æ®çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·")
    st.markdown("---")
    
    X, y, df = load_data()
    model = load_model()
    
    with st.expander("ğŸ“Š æ¨¡å‹æ€§èƒ½", expanded=False):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("å†³å®šç³»æ•°(RÂ²)", f"{r2:.4f}")
        with col2:
            st.metric("å¹³å‡ç»å¯¹è¯¯å·®(MAE)", f"Â¥{mae:.2f}")
    
    st.markdown("---")
    st.subheader("ğŸ“ è¢«ä¿é™©äººä¿¡æ¯")
    
    col1, col2 = st.columns(2)
    with col1:
        age = st.number_input("å¹´é¾„", min_value=0, max_value=100, value=30, step=1)
        gender = st.radio("æ€§åˆ«", options=["ç”·æ€§", "å¥³æ€§"], horizontal=True)
        children = st.number_input("å­å¥³æ•°é‡", min_value=0, max_value=10, value=0, step=1)
    
    with col2:
        smoker = st.radio("æ˜¯å¦å¸çƒŸ", options=["å¦", "æ˜¯"], horizontal=True)
        region = st.selectbox("åŒºåŸŸ", options=df["åŒºåŸŸ"].unique().tolist())
        bmi = st.number_input("BMIæŒ‡æ•°", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
    
    st.markdown("---")
    if st.button("ğŸš€ é¢„æµ‹åŒ»ç–—è´¹ç”¨", type="primary"):
        input_data = pd.DataFrame({
            "å¹´é¾„": [age],
            "æ€§åˆ«": [gender],
            "å­å¥³æ•°é‡": [children],
            "æ˜¯å¦å¸çƒŸ": [smoker],
            "åŒºåŸŸ": [region]
        })
        
        try:
            prediction = model.predict(input_data)[0]
            st.success("é¢„æµ‹å®Œæˆï¼")
            st.markdown("---")
            st.subheader(f"ğŸ’° é¢„è®¡å¹´åº¦åŒ»ç–—è´¹ç”¨ï¼šÂ¥{prediction:,.2f}")
            
            warnings = []
            if smoker == "æ˜¯": warnings.append("å¸çƒŸä¼šæ˜¾è‘—å¢åŠ åŒ»ç–—è´¹ç”¨é£é™©")
            if bmi > 30: warnings.append("BMIè¿‡é«˜å¯èƒ½å¢åŠ å¥åº·é£é™©")
            if age > 60: warnings.append("å¹´é¾„è¾ƒå¤§ï¼ŒåŒ»ç–—è´¹ç”¨é£é™©è¾ƒé«˜")
            if warnings:
                st.markdown("---")
                for w in warnings:
                    st.warning(f"âš ï¸ {w}")
                    
        except Exception as e:
            st.error(f"é¢„æµ‹å¤±è´¥ï¼š{str(e)}")
    
    with st.expander("ğŸ“‹ CSVæ•°æ®é¢„è§ˆ", expanded=False):
        st.dataframe(df.head(10), use_container_width=True)

if __name__ == "__main__":
    main()
