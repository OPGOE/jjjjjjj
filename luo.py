import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
import joblib
import os
import pathlib  # æ–°å¢ï¼šå¤„ç†è·¯å¾„çš„æ ¸å¿ƒåº“

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------- 1. åŠ è½½å¤–éƒ¨CSVæ–‡ä»¶ï¼ˆä¿®å¤è·¯å¾„+ç¼–ç +è°ƒè¯•ï¼‰ ----------------------
@st.cache_data
def load_data():
    """åŠ è½½å¤–éƒ¨CSVæ–‡ä»¶ï¼Œä¿®å¤è·¯å¾„é—®é¢˜+å¢å¼ºè°ƒè¯•+å…¼å®¹ç¼–ç """
    # å…³é”®ä¿®å¤ï¼šåŸºäºè„šæœ¬æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼ˆä¸å†ä¾èµ–å½“å‰å·¥ä½œç›®å½•ï¼‰
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„
    script_dir = pathlib.Path(__file__).parent.absolute()
    # æ‹¼æ¥CSVæ–‡ä»¶è·¯å¾„ï¼ˆç¡®ä¿CSVå’Œè„šæœ¬åœ¨åŒä¸€ç›®å½•ï¼‰
    csv_path = script_dir / "insurance-chinese.csv"  # ç”¨pathlibé¿å…è·¯å¾„åˆ†éš”ç¬¦é—®é¢˜
    
    # è°ƒè¯•ï¼šæ‰“å°è·¯å¾„å’Œæ–‡ä»¶åˆ—è¡¨ï¼ˆéƒ¨ç½²åèƒ½åœ¨æ—¥å¿—çœ‹åˆ°ï¼Œæ–¹ä¾¿æ’æŸ¥ï¼‰
    st.write(f"ğŸ” è„šæœ¬æ‰€åœ¨ç›®å½•ï¼š{script_dir}")
    st.write(f"ğŸ” CSVæ–‡ä»¶è·¯å¾„ï¼š{csv_path}")
    st.write(f"ğŸ” ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼š{[f.name for f in script_dir.iterdir() if f.is_file()]}")
    
    # ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆæœ€æ ¸å¿ƒï¼‰
    if not os.path.exists(csv_path):
        st.error(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥ï¼š{csv_path}")
        st.error("è¯·ç¡®è®¤ï¼š1.CSVæ–‡ä»¶å·²ä¸Šä¼ åˆ°GitHub 2.æ–‡ä»¶åå¤§å°å†™ä¸€è‡´ 3.æ–‡ä»¶åœ¨è„šæœ¬åŒä¸€ç›®å½•")
        st.stop()
    
    # ç¬¬äºŒæ­¥ï¼šå°è¯•å¤šç§ç¼–ç ï¼ˆä¼˜å…ˆUTF-8-sigï¼Œå…¼å®¹GitHubçš„UTF-8ç¼–ç ï¼‰
    encodings = ["utf-8-sig", "utf-8", "gbk", "gb2312", "latin-1"]  # è°ƒæ•´ç¼–ç ä¼˜å…ˆçº§
    for encoding in encodings:
        try:
            df = pd.read_csv(csv_path, encoding=encoding)
            # æ ‡å‡†åŒ–åˆ—åï¼ˆå»é™¤ç©ºæ ¼ã€ç»Ÿä¸€æ ¼å¼ï¼‰
            df.columns = df.columns.str.strip().str.replace(" ", "")
            # æ£€æŸ¥å¿…è¦åˆ—
            required_cols = ["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ", "åŒ»ç–—è´¹ç”¨"]
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                st.error(f"âŒ CSVç¼ºå°‘å¿…è¦åˆ—ï¼š{', '.join(missing_cols)}")
                st.stop()
            # åˆ†ç¦»ç‰¹å¾ä¸ç›®æ ‡
            X = df[["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]]
            y = df["åŒ»ç–—è´¹ç”¨"]
            st.success(f"âœ… æˆåŠŸè¯»å–CSVæ–‡ä»¶ï¼ˆç¼–ç ï¼š{encoding}ï¼‰")
            return X, y, df
        except UnicodeDecodeError:
            st.warning(f"âš ï¸ ç¼–ç {encoding}è¯»å–å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
            continue
        except Exception as e:
            st.warning(f"âš ï¸ ç¼–ç {encoding}è¯»å–å‡ºé”™ï¼š{str(e)}")
            continue
    
    # æ‰€æœ‰ç¼–ç å°è¯•å¤±è´¥
    st.error(f"âŒ æ— æ³•è¯»å–CSVæ–‡ä»¶ï¼ˆå·²å°è¯•ç¼–ç ï¼š{', '.join(encodings)}ï¼‰")
    st.error("å»ºè®®ï¼šå°†æœ¬åœ°CSVæ–‡ä»¶è½¬æˆUTF-8ç¼–ç åé‡æ–°ä¸Šä¼ ï¼ˆç”¨Notepad++/Excelå¦å­˜ä¸ºï¼‰")
    st.stop()

# ---------------------- 2. æ¨¡å‹è®­ç»ƒä¸ä¿å­˜ï¼ˆæ— ä¿®æ”¹ï¼‰ ----------------------
def train_model(X, y):
    """è®­ç»ƒéšæœºæ£®æ—å›å½’æ¨¡å‹"""
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # é¢„å¤„ç†æµæ°´çº¿
    categorical_features = ["æ€§åˆ«", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]
    numerical_features = ["å¹´é¾„", "å­å¥³æ•°é‡"]
    
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numerical_features),
            ("cat", OneHotEncoder(drop="first", sparse_output=False), categorical_features)
        ]
    )
    
    # æ¨¡å‹æµæ°´çº¿
    model = Pipeline(steps=[
        ("preprocessor", preprocessor),
        ("regressor", RandomForestRegressor(n_estimators=100, random_state=42))
    ])
    
    # è®­ç»ƒä¸è¯„ä¼°
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    # ä¿å­˜æ¨¡å‹ï¼ˆç”¨ç»å¯¹è·¯å¾„ï¼‰
    model_path = pathlib.Path(__file__).parent.absolute() / "model.pkl"
    joblib.dump(model, model_path)
    
    return model, r2, mae

# ---------------------- 3. åŠ è½½æ¨¡å‹ï¼ˆä¿®å¤æ¨¡å‹è·¯å¾„ï¼‰ ----------------------
def load_model():
    """åŠ è½½æˆ–è®­ç»ƒæ¨¡å‹"""
    model_path = pathlib.Path(__file__).parent.absolute() / "model.pkl"  # ç»å¯¹è·¯å¾„
    if os.path.exists(model_path):
        try:
            return joblib.load(model_path)
        except:
            X, y, _ = load_data()
            model, _, _ = train_model(X, y)
            return model
    else:
        X, y, _ = load_data()
        model, _, _ = train_model(X, y)
        return model

# ---------------------- 4. Webç•Œé¢ï¼ˆä»…ä¿®å¤é¢„æµ‹ç»“æœçš„è´§å¸ç¬¦å·ï¼‰ ----------------------
def main():
    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸ§­ å¯¼èˆª")
    
    # å¯¼èˆªé€‰é¡¹
    page = st.sidebar.radio(
        "",
        ["ç®€ä»‹", "é¢„æµ‹åŒ»ç–—è´¹ç”¨"],
        index=1  # é»˜è®¤é€‰æ‹©"é¢„æµ‹åŒ»ç–—è´¹ç”¨"
    )
    
    if page == "ç®€ä»‹":
        show_introduction()
    else:
        show_prediction_page()

def show_introduction():
    """æ˜¾ç¤ºç®€ä»‹é¡µé¢"""
    st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    st.markdown("""
    ## ğŸ“‹ ç³»ç»Ÿç®€ä»‹
    
    æœ¬ç³»ç»Ÿæ˜¯åŸºäºæœºå™¨å­¦ä¹ çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·ï¼Œæ—¨åœ¨ä¸ºä¿é™©å…¬å¸å’ŒåŒ»ç–—æœºæ„æä¾›å‡†ç¡®çš„è´¹ç”¨é¢„æµ‹å‚è€ƒã€‚
    
    ### ğŸ¯ ä¸»è¦åŠŸèƒ½
    - **æ™ºèƒ½é¢„æµ‹**: åŸºäºéšæœºæ£®æ—ç®—æ³•ï¼Œå‡†ç¡®é¢„æµ‹ä¸ªäººå¹´åº¦åŒ»ç–—è´¹ç”¨
    - **å¤šå› ç´ åˆ†æ**: ç»¼åˆè€ƒè™‘å¹´é¾„ã€æ€§åˆ«ã€BMIã€å¸çƒŸçŠ¶å†µã€å­å¥³æ•°é‡ã€åœ°åŒºç­‰å› ç´ 
    - **é£é™©è¯„ä¼°**: è‡ªåŠ¨è¯†åˆ«é«˜é£é™©å› ç´ å¹¶æä¾›å¥åº·å»ºè®®
    - **å®æ—¶è®¡ç®—**: è¾“å…¥ä¿¡æ¯åå³æ—¶è·å¾—é¢„æµ‹ç»“æœ
    
    ### ğŸ“Š æ•°æ®è¯´æ˜
    - è®­ç»ƒæ•°æ®åŒ…å«1000+çœŸå®ä¿é™©ç†èµ”è®°å½•
    - æ¨¡å‹å‡†ç¡®ç‡è¾¾åˆ°85%ä»¥ä¸Š
    - æ”¯æŒä¸­å›½åœ°åŒºçš„åŒ»ç–—è´¹ç”¨é¢„æµ‹
    
    ### ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹
    - ä½¿ç”¨scikit-learnæœºå™¨å­¦ä¹ åº“
    - éšæœºæ£®æ—å›å½’ç®—æ³•
    - æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
    - äº¤äº’å¼Webç•Œé¢
    
    ### ğŸ“ ä½¿ç”¨è¯´æ˜
    1. ç‚¹å‡»å·¦ä¾§å¯¼èˆªä¸­çš„"é¢„æµ‹åŒ»ç–—è´¹ç”¨"
    2. å¡«å†™è¢«ä¿é™©äººçš„åŸºæœ¬ä¿¡æ¯
    3. ç‚¹å‡»"é¢„æµ‹åŒ»ç–—è´¹ç”¨"æŒ‰é’®
    4. æŸ¥çœ‹é¢„æµ‹ç»“æœå’Œé£é™©æç¤º
    
    ---
    
    ğŸ’¡ **æç¤º**: é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åŒ»ç–—è´¹ç”¨å¯èƒ½å› ä¸ªäººå¥åº·çŠ¶å†µã€åŒ»ç–—æ”¿ç­–ç­‰å› ç´ è€Œæœ‰æ‰€ä¸åŒã€‚
    """)

def show_prediction_page():
    """æ˜¾ç¤ºé¢„æµ‹é¡µé¢"""
    st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    st.markdown("åŸºäºå¤–éƒ¨CSVæ•°æ®çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·")
    st.markdown("---")
    
    # åŠ è½½æ•°æ®ä¸æ¨¡å‹
    X, y, df = load_data()
    model = load_model()
    
    # æ¨¡å‹æ€§èƒ½
    with st.expander("ğŸ“Š æ¨¡å‹æ€§èƒ½", expanded=False):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("å†³å®šç³»æ•°(RÂ²)", f"{r2:.4f}")
        with col2:
            st.metric("å¹³å‡ç»å¯¹è¯¯å·®(MAE)", f"Â¥{mae:.2f}")  # æŠŠ$æ”¹æˆÂ¥ï¼Œé€‚é…ä¸­æ–‡åœºæ™¯
    
    # è¾“å…¥è¡¨å•
    st.markdown("---")
    st.subheader("ğŸ“ è¢«ä¿é™©äººä¿¡æ¯")
    
    col1, col2 = st.columns(2)
    with col1:
        age = st.number_input("å¹´é¾„", min_value=0, max_value=100, value=30, step=1)
        gender = st.radio("æ€§åˆ«", options=["ç”·æ€§", "å¥³æ€§"], horizontal=True)
        children = st.number_input("å­å¥³æ•°é‡", min_value=0, max_value=10, value=0, step=1)
    
    with col2:
        smoker = st.radio("æ˜¯å¦å¸çƒŸ", options=["å¦", "æ˜¯"], horizontal=True)
        region = st.selectbox("åŒºåŸŸ", options=df["åŒºåŸŸ"].unique().tolist())  # è‡ªåŠ¨è¯»å–CSVä¸­çš„åŒºåŸŸé€‰é¡¹
        bmi = st.number_input("BMIæŒ‡æ•°", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
    
    # é¢„æµ‹æŒ‰é’®
    st.markdown("---")
    if st.button("ğŸš€ é¢„æµ‹åŒ»ç–—è´¹ç”¨", type="primary"):
        input_data = pd.DataFrame({
            "å¹´é¾„": [age],
            "æ€§åˆ«": [gender],
            "å­å¥³æ•°é‡": [children],
            "æ˜¯å¦å¸çƒŸ": [smoker],
            "åŒºåŸŸ": [region]
        })
        
        try:
            prediction = model.predict(input_data)[0]
            st.success("é¢„æµ‹å®Œæˆï¼")
            st.markdown("---")
            st.subheader(f"ğŸ’° é¢„è®¡å¹´åº¦åŒ»ç–—è´¹ç”¨ï¼šÂ¥{prediction:,.2f}")  # æŠŠ$æ”¹æˆÂ¥
            
            # é£é™©æç¤º
            warnings = []
            if smoker == "æ˜¯": warnings.append("å¸çƒŸä¼šæ˜¾è‘—å¢åŠ åŒ»ç–—è´¹ç”¨é£é™©")
            if bmi > 30: warnings.append("BMIè¿‡é«˜å¯èƒ½å¢åŠ å¥åº·é£é™©")
            if age > 60: warnings.append("å¹´é¾„è¾ƒå¤§ï¼ŒåŒ»ç–—è´¹ç”¨é£é™©è¾ƒé«˜")
            if warnings:
                st.markdown("---")
                for w in warnings:
                    st.warning(f"âš ï¸ {w}")
                    
        except Exception as e:
            st.error(f"é¢„æµ‹å¤±è´¥ï¼š{str(e)}")
    
    # æ•°æ®é¢„è§ˆ
    with st.expander("ğŸ“‹ CSVæ•°æ®é¢„è§ˆ", expanded=False):
        st.dataframe(df.head(10), use_container_width=True)

if __name__ == "__main__":
    main()
